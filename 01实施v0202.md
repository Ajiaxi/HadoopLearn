# hadoop1.0 与 hadoop 2.0 对比

3大核心模块

* \*\*Hadoop Distributed File System \(HDFS\)\*\*: 一个分布式文件系统

\* \*\*Hadoop YARN\*\*: 作业调度及集群的资源管理

\* \*\*Hadoop MapReduce\*\*: 基于YARN的并行大数据处理

\#\#\#\#\# 其它Hadoop的子项目

\|项目\|说明\|贡献者\|

\|:--\|:--\|:--\|

\|\*\*Ambari\*\*\|一种基于Web的工具，支持Apache Hadoop集群的供应（安装）、管理和监控。Ambari目前已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等\|\|

\|\*\*Avro\*\*\|一个数据序列化的系统\|\|

\|\*\*Cassandra\*\*\| 一套开源分布式NoSQL数据库系统（更适合于实时事务处理和提供交互型数据）\|facebook\|

\|\*\*Chukwa\*\*\| 一个开源的用于监控大型分布式系统的数据收集系统,可以用于监控大规模\(2000+ 以上的节点, 每天产生数据量在T级别\) hadoop 集群的整体运行情况并对它们的日志进行分析 \|\|

\|\*\*HBase\*\*\|一套开源分布式NoSQL数据库系统\(日志级一致性，更加适合于数据仓库、大型数据的处理和分析\).\|\|

\|\*\*Hive\*\*\|可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析（facebook提供）\|\|

\|\*\*Mahout\*\*\| 提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序，通过使用Hadoop，Mahout可以有效地扩展到云中\|\|

\|\*\*Pig\*\*\| Pig可以看做hadoop的客户端软件,可以连接到hadoop集群进行数据分析工作，方便不熟悉java的用户,使用一种较为简便的类似于SQL的面向数据流的语言pig latin进行数据处理（Yahoo提供）\|\|

\|\*\*Spark\*\*\|A fast and general compute engine for Hadoop data. Spark provides a simple and expressive programming model that supports a wide range of applications, including ETL, machine learning, stream processing, and graph computation.\|\|

\|\*\*Tez\*\*\|A generalized data-flow programming framework, built on Hadoop YARN, which provides a powerful and flexible engine to execute an arbitrary DAG of tasks to process data for both batch and interactive use-cases. Tez is being adopted by \* Hive™, Pig™ and other frameworks in the Hadoop ecosystem, and also by other commercial software \(e.g. ETL tools\), to replace Hadoop™ MapReduce as the underlying execution engine.\|\|

\|\*\*ZooKeeper\*\*\|A high-performance coordination service for distributed applications.\|\|

\#\# 环境

\* linux

\* \[Oracle java jdk\]\(http:\/\/www.oracle.com\/technetwork\/java\/javase\/downloads\/jdk8-downloads-2133151.html\) hadoop的运行环境

\* ssh hadoop集群间通信的需要用到

\* vi hadoop有很多配置文件要配置

\* perl hadoop有些代码是用per写的

\[jdk安装\]\(http:\/\/jingyan.baidu.com\/article\/59703552e002e18fc007403b.html\)

\[perl安装\]\(http:\/\/blog.csdn.net\/junweifan\/article\/details\/7260401\)

解压

\`\`\`

sudo tar zxvf .\/jdk-8u5-linux-x64.tar.gz -C ..\/..\/..\/usr\/lib\/jvm

\`\`\`

配置环境变量

\`\`\`

$ vim ~\/.bashrc

\`\`\`

或

\`\`\`

$ vim ~\/.bash\_profile

\`\`\`

\`\`\`

export JAVA\_HOME=\/usr\/lib\/jvm\/java-8u5-sun

export JRE\_HOME=${JAVA\_HOME}\/jre

export CLASSPATH=.:${JAVA\_HOME}\/lib:${JRE\_HOME}\/lib

export PATH=${JAVA\_HOME}\/bin:$PATH

\`\`\`

\`\`\`

source ~\/.bashrc

\`\`\`

\#\# 三种运行模式

1. 单机模式：安装简单，几乎不用配置，但仅限于调试

2. 伪分布模式：在单节点上同时启动namenode、datanode、jobtracker、tasktracker、secondary namenode等5个进程，模拟分布式运行的各个节点

3. 完全分布模式：正常的Hadoop集群，由多个各司其职的节点构成


\#\# 伪分布式模式的安装与配置

1. 下载并解压Hadoop安装包，为了和教材一致，选用了0.20.2版本

2. 进入Hadoop的解压目录，编辑conf\/hadoop-env.sh文件（注意：0.23版后配置文件的位置有所变化）

3. 编辑conf目录下core-site.xml、hdfs-site.xml和mapred-site.xml三个核心配置文件

4. 配置ssh，生成密钥，使到（节点间）可以免密码连接

5. 格式化HDFS

6. 使用bin\/start-all.sh启动Hadoop

7. 使用bin\/stop-all.sh关闭Hadoop


\#\#\# Step 1 下载

hadoop镜像

\[http:\/\/mirror.bit.edu.cn\/apache\/hadoop\/common\/\]\(http:\/\/mirror.bit.edu.cn\/apache\/hadoop\/common\/\)

\[http:\/\/mirrors.cnnic.cn\/apache\/hadoop\/common\/\]\(http:\/\/mirrors.cnnic.cn\/apache\/hadoop\/common\/\)

\#\#\# Step 2、3 配置文件

\|文件\|格式\|说明\|

\|:--\|:--\|:--\|

\|hadoop-env.sh\|bash脚本\|在运行Hadoop的脚本中使用的环境变量\|

\|core-site.xml\|Hadoop配置XML\|Hadoop核心的配置，例如HDFS和MapReduce中很普遍的I\/O设置\|

\|hdfs-site.xml\|Hadoop配置XML\|HDFS后台程序设置的配置：名称节点，第二名称节点和数据节点\|

\|mapred-site.xml\|Hadoop配置XML\|MapReduce后台程序设置的配置：jobtracker和tasktracker\|

\|masters\|文本\|记录运行第二名称节点的机器\(一行一个\)的列表\|

\|slaves\|文本\|记录运行数据节点和tasktracker的机器\(一行一个\)的列表\|

\|hadoop-metrices.properties\|Java属性\|控制Hadoop怎么发布metries\(参见第10章\)的属性\|

\|log4j.properties\|Java属性\|系统日志文件属性，名称节点审计日志和tasktracker子进程\(参见第5章\)的日志属性\|

\#\#\#\#\#\# 1 修改hadoop-env.sh \(详见《权威指南》\)

配置jdk目录，新版已不需要配置

\`\`\`

\# The java implementation to use.

export JAVA\_HOME=\/usr\/java\/jdk1.6.0\_26

\`\`\`

\#\#\#\#\#\# 2 修改core-site.xml

设置集群中nodename节点的IP和端口

\`\`\`

&lt;configuration&gt;

&lt;property&gt;

&lt;name&gt;fs.default.name&lt;\/name&gt;

&lt;value&gt;hdfs:\/\/localhost:9000&lt;\/value&gt;

&lt;description&gt;集群中nodename节点的IP和端口，2X版本为fs.defaultFS&lt;\/description&gt;

&lt;\/property&gt;

&lt;property&gt;

&lt;name&gt;hadoop.tmp.dir&lt;\/name&gt;

&lt;value&gt;\/Users\/jason\/hadoop\_data\/temp&lt;\/value&gt;

&lt;\/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.name.dir&lt;\/name&gt;

&lt;value&gt;\/Users\/jason\/hadoop\_data\/dfs\/name&lt;\/value&gt;

&lt;\/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.data.dir&lt;\/name&gt;

&lt;value&gt;\/Users\/jason\/hadoop\_data\/dfs\/data&lt;\/value&gt;

&lt;\/property&gt;

&lt;\/configuration&gt;

\`\`\`

\#\#\#\#\#\# 3 修改hdfs-site.xml

1. 配置相同数据块在集群中的个数

2. datanode中确定将数据保存在什么目录下


\`\`\`

&lt;configuration&gt;

&lt;property&gt;

&lt;!--相同数据块在集群中的个数--&gt;

&lt;name&gt;dfs.replication&lt;\/name&gt;

&lt;value&gt;1&lt;\/value&gt;

&lt;\/property&gt;

&lt;property&gt;

&lt;!-- datanode中确定将数据保存在什么目录下，目录需已存在--&gt;

&lt;!-- 2x版本使用dfs.datanode.data.dir --&gt;

&lt;name&gt;dfs.data.dir&lt;\/name&gt;

&lt;value&gt;file:\/usr\/local\/hadoop\/tmp\/dfs\/data&lt;\/value&gt;

&lt;\/property&gt;

&lt;\/configuration&gt;

\`\`\`

\#\#\#\#\#\# 4 修改mapred-site.xml

配置作业跟踪器\(Job tracker\)所在的IP和端口

\`\`\`

&lt;configuration&gt;

&lt;property&gt;

&lt;name&gt;mapred.job.tracker&lt;\/name&gt;

&lt;value&gt;localhost:9001&lt;\/value&gt;&gt;

&lt;\/property&gt;

&lt;\/configuration&gt;

\`\`\`

\#\#\# Step 4 配置ssh

为当前用户创建一个密钥

\`\`\`

ssh-keygen -t rsa

\`\`\`

复制公钥

\`\`\`

cp id\_rsa.pub authorized\_keys

\`\`\`

ssh 配置完成\(在集群的所有节点中做同样操作\)

\#\#\# Step 5 格式化HDFS\(在namenode节点执行\)

\`\`\`

bin\/hadoop namenode -format

\`\`\`

\#\#\# Step 6 启动Hadoop\(在namenode节点执行\)

\`\`\`

bin\/start-all.sh

\`\`\`

\#\# 完全布式模式的安装与配置

1. 配置hosts文件\(集群变大时可考滤使用自已的DNS，方便维护\)

2. 建立hadoop运行账号\(为hadoop添加专业的账号\)

3. 使用hadoop账号登录

4. 配置ssh

5. 下载并解压hadoop安装包

6. 配置namenode，修改site\(同伪分布，注意 hdfs-site.xml中的datanode的个数\)

7. 配置hadoop-env.sh（修改JDK目录，同伪分布）

8. 配置masters和slaves

9. 向各节点复制hadoop

10. 格式化namenode

11. 启动hadoop

12. 用jps检验各后台进程是否成功启动


\#\#\# Step 1 配置hosts文件

\(集群变大时可考滤使用自已的DNS，方便维护\)

\`\`\`

vim \/etc\/hosts

\`\`\`

\#\#\# Step 4 配置ssh

为当前用户创建一个密钥

\`\`\`

ssh-kengen -t rsa

\`\`\`

复制公钥

\`\`\`

cp id\_rsa.pub authorized\_keys

\`\`\`

ssh 配置完成\(在集群的所有节点中做同样操作\)

当所集群中所有节点都配置好ssh后，将所有节点的authorized\_keys中的内容添加到一个大的authorized\_keys，然后用这个大的authorized\_keys复盖各节点的authorized\_keys

\#\#\# Step 8 配置masters和slaves

namenode jobtracker

datanode trackertask

\#\#\# Step 9 将配置好的hadoop复制到每个节点\(一定要配置好再复制\)

-R 表示目录递归复制

\#\#\# Step 10 格式化namenode\(在namenode\)

\#\#\# Step 11 启动hadoop\(在namenode\)

\#\#\# Step 12 用jps检验各后台进程是否成功启动

Master

Slave

